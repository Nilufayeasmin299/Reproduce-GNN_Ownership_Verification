{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOd/2jcC9bkuQrizCjVaDVc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nilufayeasmin299/Reproduce-GNN_Ownership_Verification/blob/main/GNN_reproduction_with_different_settings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W16kPUXaBiZ",
        "outputId": "697a2114-45f8-4de4-e7e4-4a57ea5a668d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.9)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torch-geometric numpy scikit-learn matplotlib tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GINConv\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os"
      ],
      "metadata": {
        "id": "WXXczV0F0ObL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "id": "Rk2flS-D5Xu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "OEiyrHCt5bFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedGNN(nn.Module):\n",
        "    \"\"\"Enhanced GNN model with multiple architectures support\"\"\"\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2,\n",
        "                 dropout=0.5, arch='GCN'):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.arch = arch\n",
        "\n",
        "        # Initialize layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.batch_norms = nn.ModuleList()\n",
        "\n",
        "        # Input layer\n",
        "        if arch == 'GCN':\n",
        "            self.convs.append(GCNConv(in_channels, hidden_channels))\n",
        "        elif arch == 'GAT':\n",
        "            self.convs.append(GATConv(in_channels, hidden_channels))\n",
        "        elif arch == 'SAGE':\n",
        "            self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
        "        elif arch == 'GIN':\n",
        "            gin_nn = nn.Sequential(\n",
        "                nn.Linear(in_channels, hidden_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_channels, hidden_channels)\n",
        "            )\n",
        "            self.convs.append(GINConv(gin_nn))\n",
        "\n",
        "        self.batch_norms.append(nn.BatchNorm1d(hidden_channels))\n",
        "\n",
        "        # Hidden layers\n",
        "        for _ in range(num_layers - 2):\n",
        "            if arch == 'GCN':\n",
        "                self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
        "            elif arch == 'GAT':\n",
        "                self.convs.append(GATConv(hidden_channels, hidden_channels))\n",
        "            elif arch == 'SAGE':\n",
        "                self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
        "            elif arch == 'GIN':\n",
        "                gin_nn = nn.Sequential(\n",
        "                    nn.Linear(hidden_channels, hidden_channels),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(hidden_channels, hidden_channels)\n",
        "                )\n",
        "                self.convs.append(GINConv(gin_nn))\n",
        "            self.batch_norms.append(nn.BatchNorm1d(hidden_channels))\n",
        "\n",
        "        # Output layer\n",
        "        if arch == 'GCN':\n",
        "            self.convs.append(GCNConv(hidden_channels, out_channels))\n",
        "        elif arch == 'GAT':\n",
        "            self.convs.append(GATConv(hidden_channels, out_channels))\n",
        "        elif arch == 'SAGE':\n",
        "            self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
        "        elif arch == 'GIN':\n",
        "            gin_nn = nn.Sequential(\n",
        "                nn.Linear(hidden_channels, hidden_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_channels, out_channels)\n",
        "            )\n",
        "            self.convs.append(GINConv(gin_nn))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Forward pass through layers\n",
        "        for i in range(self.num_layers - 1):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = self.batch_norms[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.convs[-1](x, edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "u3XMW1m45e5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VerificationClassifier(nn.Module):\n",
        "    \"\"\"Enhanced classifier for ownership verification\"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            # First layer\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            # Second layer\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.BatchNorm1d(hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            # Third layer\n",
        "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
        "            nn.BatchNorm1d(hidden_dim // 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            # Output layer\n",
        "            nn.Linear(hidden_dim // 4, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n"
      ],
      "metadata": {
        "id": "lLgztOKq5vfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNVerifier:\n",
        "    \"\"\"Enhanced GNN ownership verification system\"\"\"\n",
        "    def __init__(self, hidden_dim=128, mask_ratio=0.1, lr=0.001, weight_decay=1e-4):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.mask_ratio = mask_ratio\n",
        "        self.lr = lr\n",
        "        self.weight_decay = weight_decay\n",
        "        self.device = device\n",
        "\n",
        "    def create_masks(self, data):\n",
        "        \"\"\"Create feature masks with importance sampling\"\"\"\n",
        "        num_features = data.x.size(1)\n",
        "\n",
        "        # Calculate feature importance\n",
        "        feature_importance = torch.abs(data.x).mean(0)\n",
        "        importance_threshold = torch.quantile(feature_importance, self.mask_ratio)\n",
        "\n",
        "        # Create mask based on importance\n",
        "        mask = torch.ones_like(data.x)\n",
        "        mask[:, feature_importance < importance_threshold] = 0\n",
        "\n",
        "        # Apply mask\n",
        "        data.x = data.x * mask\n",
        "        return data\n",
        "\n",
        "    def extract_fingerprint(self, model, data):\n",
        "        \"\"\"Extract enhanced model fingerprint\"\"\"\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            # Forward pass\n",
        "            outputs = model(data.x, data.edge_index)\n",
        "            logits = outputs.detach()\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "\n",
        "            # Calculate fingerprint components\n",
        "            mean_logits = logits.mean(0)\n",
        "            mean_probs = probs.mean(0)\n",
        "            max_probs = probs.max(1)[0]\n",
        "            entropy = -(probs * torch.log(probs + 1e-10)).sum(1).mean()\n",
        "\n",
        "            # Layer activations\n",
        "            layer_activations = []\n",
        "            x = data.x\n",
        "            for i, conv in enumerate(model.convs[:-1]):\n",
        "                x = conv(x, data.edge_index)\n",
        "                layer_activations.append(x.mean(0))\n",
        "\n",
        "            # Combine all components\n",
        "            fingerprint = torch.cat([\n",
        "                mean_logits,\n",
        "                mean_probs,\n",
        "                max_probs.mean().unsqueeze(0),\n",
        "                entropy.unsqueeze(0),\n",
        "                *layer_activations\n",
        "            ])\n",
        "\n",
        "        return fingerprint\n",
        "\n",
        "    def train_verifier(self, target_model, shadow_models, indep_models, train_data):\n",
        "        \"\"\"Train enhanced verification classifier\"\"\"\n",
        "        # Extract fingerprints\n",
        "        target_fp = self.extract_fingerprint(target_model, train_data)\n",
        "\n",
        "        shadow_fps = []\n",
        "        for model in tqdm(shadow_models, desc=\"Processing shadow models\"):\n",
        "            fp = self.extract_fingerprint(model, train_data)\n",
        "            shadow_fps.append(fp)\n",
        "        shadow_fps = torch.stack(shadow_fps)\n",
        "\n",
        "        indep_fps = []\n",
        "        for model in tqdm(indep_models, desc=\"Processing independent models\"):\n",
        "            fp = self.extract_fingerprint(model, train_data)\n",
        "            indep_fps.append(fp)\n",
        "        indep_fps = torch.stack(indep_fps)\n",
        "\n",
        "        # Prepare training data\n",
        "        X = torch.cat([shadow_fps, indep_fps], dim=0).to(device)\n",
        "        y = torch.cat([\n",
        "            torch.ones(len(shadow_fps)),\n",
        "            torch.zeros(len(indep_fps))\n",
        "        ]).to(device)\n",
        "\n",
        "        # Create classifier\n",
        "        classifier = VerificationClassifier(\n",
        "            input_dim=target_fp.shape[0],\n",
        "            hidden_dim=self.hidden_dim\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            classifier.parameters(),\n",
        "            lr=self.lr,\n",
        "            weight_decay=self.weight_decay\n",
        "        )\n",
        "\n",
        "        # Training loop with early stopping\n",
        "        best_loss = float('inf')\n",
        "        patience = 15\n",
        "        patience_counter = 0\n",
        "        best_state = None\n",
        "\n",
        "        classifier.train()\n",
        "        for epoch in tqdm(range(300), desc=\"Training verifier\"):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = classifier(X).squeeze()\n",
        "            loss = F.binary_cross_entropy(outputs, y)\n",
        "\n",
        "            # L2 regularization\n",
        "            l2_reg = torch.tensor(0.).to(device)\n",
        "            for param in classifier.parameters():\n",
        "                l2_reg += torch.norm(param)\n",
        "            loss += 0.01 * l2_reg\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if loss.item() < best_loss:\n",
        "                best_loss = loss.item()\n",
        "                best_state = classifier.state_dict()\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                break\n",
        "\n",
        "        # Load best model\n",
        "        classifier.load_state_dict(best_state)\n",
        "        self.classifier = classifier\n",
        "        return classifier\n",
        "\n",
        "    def verify(self, classifier, target_model, suspect_model, test_data):\n",
        "        \"\"\"Verify model ownership\"\"\"\n",
        "        suspect_fp = self.extract_fingerprint(suspect_model, test_data)\n",
        "\n",
        "        classifier.eval()\n",
        "        with torch.no_grad():\n",
        "            suspect_fp = suspect_fp.unsqueeze(0).to(device)\n",
        "            score = classifier(suspect_fp.to(device)).item()\n",
        "\n",
        "        return score > 0.5\n",
        "\n",
        "def train_model(model, data, epochs=200):\n",
        "    \"\"\"Train a GNN model with improved training process\"\"\"\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_state = None\n",
        "    patience = 20\n",
        "    patience_counter = 0\n",
        "\n",
        "    model.train()\n",
        "    for epoch in tqdm(range(epochs), desc=\"Training model\"):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss = F.cross_entropy(out[data.val_mask], data.y[data.val_mask])\n",
        "        model.train()\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_state = model.state_dict()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return model"
      ],
      "metadata": {
        "id": "n2RxHUDz5zjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_performance(verifier, target_model, extracted_models, indep_models, test_data):\n",
        "    \"\"\"Evaluate verification performance\"\"\"\n",
        "    results = []\n",
        "    labels = []\n",
        "\n",
        "    # Test extracted models\n",
        "    for model in tqdm(extracted_models, desc=\"Testing extracted models\"):\n",
        "        is_extracted = verifier.verify(\n",
        "            verifier.classifier, target_model, model, test_data\n",
        "        )\n",
        "        results.append(is_extracted)\n",
        "        labels.append(1)\n",
        "\n",
        "    # Test independent models\n",
        "    for model in tqdm(indep_models, desc=\"Testing independent models\"):\n",
        "        is_extracted = verifier.verify(\n",
        "            verifier.classifier, target_model, model, test_data\n",
        "        )\n",
        "        results.append(is_extracted)\n",
        "        labels.append(0)\n",
        "\n",
        "    results = np.array(results)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': np.mean(results == labels),\n",
        "        'fpr': np.mean((results == 1) & (labels == 0)),\n",
        "        'fnr': np.mean((results == 0) & (labels == 1))\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def run_experiment(dataset_name='Cora', setting='I'):\n",
        "    \"\"\"Run complete verification experiment\"\"\"\n",
        "    print(f\"\\nRunning experiment on {dataset_name} with Setting {setting}\")\n",
        "\n",
        "    # Load dataset\n",
        "    dataset = Planetoid(root=f'/tmp/{dataset_name}', name=dataset_name, transform=NormalizeFeatures())\n",
        "    data = dataset[0].to(device)\n",
        "\n",
        "    # Set architecture and parameters based on setting\n",
        "    if setting in ['I', 'II']:\n",
        "        arch = 'GCN'\n",
        "    else:\n",
        "        arch = 'SAGE'\n",
        "\n",
        "    num_layers = 3 if setting in ['II', 'IV'] else 2\n",
        "\n",
        "    # Create target model\n",
        "    target_model = EnhancedGNN(\n",
        "        in_channels=dataset.num_features,\n",
        "        hidden_channels=128,\n",
        "        out_channels=dataset.num_classes,\n",
        "        num_layers=num_layers,\n",
        "        dropout=0.5,\n",
        "        arch=arch\n",
        "    ).to(device)\n",
        "\n",
        "    print(\"Training target model...\")\n",
        "    target_model = train_model(target_model, data)\n",
        "\n",
        "    # Create and train shadow models\n",
        "    print(\"\\nTraining shadow models...\")\n",
        "    shadow_models = []\n",
        "    for i in range(10):\n",
        "        model = EnhancedGNN(\n",
        "            in_channels=dataset.num_features,\n",
        "            hidden_channels=128,\n",
        "            out_channels=dataset.num_classes,\n",
        "            num_layers=num_layers,\n",
        "            dropout=0.5,\n",
        "            arch=arch\n",
        "        ).to(device)\n",
        "        shadow_models.append(train_model(model, data))\n",
        "\n",
        "    # Create and train independent models\n",
        "    print(\"\\nTraining independent models...\")\n",
        "    indep_models = []\n",
        "    architectures = ['GCN', 'GAT', 'SAGE', 'GIN']\n",
        "    for i in range(10):\n",
        "        model = EnhancedGNN(\n",
        "            in_channels=dataset.num_features,\n",
        "            hidden_channels=128,\n",
        "            out_channels=dataset.num_classes,\n",
        "            num_layers=num_layers,\n",
        "            dropout=0.5,\n",
        "            arch=architectures[i % len(architectures)]\n",
        "        ).to(device)\n",
        "        indep_models.append(train_model(model, data))\n",
        "\n",
        "    # Initialize and train verifier\n",
        "    print(\"\\nTraining verifier...\")\n",
        "    #verifier = GN\n",
        "    # Initialize and train verifier\n",
        "    print(\"\\nTraining verifier...\")\n",
        "    verifier = GNNVerifier(\n",
        "        hidden_dim=128,\n",
        "        mask_ratio=0.1,\n",
        "        lr=0.001,\n",
        "        weight_decay=1e-4\n",
        "    )\n",
        "\n",
        "    verifier.train_verifier(target_model, shadow_models, indep_models, data)\n",
        "\n",
        "    # Evaluate performance\n",
        "    print(\"\\nEvaluating performance...\")\n",
        "    metrics = evaluate_performance(\n",
        "        verifier,\n",
        "        target_model,\n",
        "        shadow_models[:5],  # Use half for testing\n",
        "        indep_models[:5],   # Use half for testing\n",
        "        data\n",
        "    )\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "vxo6yljv59FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    # List of datasets and settings to test\n",
        "    datasets = ['Cora', 'CiteSeer', 'PubMed']\n",
        "    settings = ['I', 'II', 'III', 'IV']\n",
        "\n",
        "    # Store results\n",
        "    all_results = {}\n",
        "\n",
        "    # Run experiments\n",
        "    for dataset in datasets:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Running experiments on {dataset} dataset\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        dataset_results = {}\n",
        "        for setting in settings:\n",
        "            # Run experiment\n",
        "            metrics = run_experiment(dataset, setting)\n",
        "\n",
        "            # Store results\n",
        "            dataset_results[setting] = metrics\n",
        "\n",
        "            # Print results\n",
        "            print(f\"\\nResults for Setting {setting}:\")\n",
        "            print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "            print(f\"False Positive Rate: {metrics['fpr']:.4f}\")\n",
        "            print(f\"False Negative Rate: {metrics['fnr']:.4f}\")\n",
        "\n",
        "        all_results[dataset] = dataset_results\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\n\\n\" + \"=\"*50)\n",
        "    print(\"FINAL RESULTS SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for dataset in datasets:\n",
        "        print(f\"\\n{dataset} Dataset:\")\n",
        "        for setting in settings:\n",
        "            metrics = all_results[dataset][setting]\n",
        "            print(f\"\\nSetting {setting}:\")\n",
        "            print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "            print(f\"False Positive Rate: {metrics['fpr']:.4f}\")\n",
        "            print(f\"False Negative Rate: {metrics['fnr']:.4f}\")\n"
      ],
      "metadata": {
        "id": "YXtu4vth6Hmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtBTuzBI8uV5",
        "outputId": "7d2bb216-4dac-40f7-fa91-b55a98e05886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Ensure CUDA is available\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"CUDA is available. Using GPU:\", torch.cuda.get_device_name(0))\n",
        "    else:\n",
        "        print(\"CUDA is not available. Using CPU\")\n",
        "\n",
        "    # Run main function\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVI2nj1A6UO3",
        "outputId": "35f0552c-a5a4-440f-b4b1-c0675413a3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. Using GPU: Tesla T4\n",
            "\n",
            "==================================================\n",
            "Running experiments on Cora dataset\n",
            "==================================================\n",
            "\n",
            "Running experiment on Cora with Setting I\n",
            "Training target model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▏        | 24/200 [00:00<00:00, 207.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training shadow models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  14%|█▍        | 28/200 [00:00<00:00, 215.85it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:00, 228.10it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:00, 233.61it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:00, 204.63it/s]\n",
            "Training model:  14%|█▍        | 28/200 [00:00<00:00, 219.24it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:00, 189.10it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:00, 220.70it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:00, 243.49it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:00, 216.42it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:00, 177.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training independent models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  14%|█▎        | 27/200 [00:00<00:00, 192.36it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 145.86it/s]\n",
            "Training model:  14%|█▍        | 29/200 [00:00<00:01, 162.66it/s]\n",
            "Training model:  16%|█▋        | 33/200 [00:00<00:00, 180.56it/s]\n",
            "Training model:  14%|█▍        | 28/200 [00:00<00:00, 233.78it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:01, 110.32it/s]\n",
            "Training model:  16%|█▋        | 33/200 [00:00<00:01, 105.31it/s]\n",
            "Training model:  16%|█▋        | 33/200 [00:00<00:01, 93.37it/s] \n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 80.79it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:03, 49.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training verifier...\n",
            "\n",
            "Training verifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing shadow models: 100%|██████████| 10/10 [00:00<00:00, 122.98it/s]\n",
            "Processing independent models: 100%|██████████| 10/10 [00:00<00:00, 147.89it/s]\n",
            "Training verifier:  46%|████▋     | 139/300 [00:01<00:01, 81.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating performance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing extracted models: 100%|██████████| 5/5 [00:00<00:00, 86.12it/s]\n",
            "Testing independent models: 100%|██████████| 5/5 [00:00<00:00, 84.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Setting I:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Running experiment on Cora with Setting II\n",
            "Training target model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▎        | 25/200 [00:00<00:02, 62.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training shadow models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▎        | 25/200 [00:00<00:02, 81.01it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 103.17it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:02, 81.28it/s]\n",
            "Training model:  14%|█▎        | 27/200 [00:00<00:01, 87.66it/s]\n",
            "Training model:  14%|█▍        | 28/200 [00:00<00:01, 89.37it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:02, 82.11it/s]\n",
            "Training model:  14%|█▎        | 27/200 [00:00<00:02, 85.03it/s] \n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 105.14it/s]\n",
            "Training model:  14%|█▎        | 27/200 [00:00<00:02, 84.14it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 104.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training independent models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 111.30it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:02, 59.15it/s]\n",
            "Training model:  14%|█▎        | 27/200 [00:00<00:01, 103.00it/s]\n",
            "Training model:  14%|█▍        | 29/200 [00:00<00:01, 116.21it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:02, 84.37it/s]\n",
            "Training model:  14%|█▎        | 27/200 [00:00<00:02, 76.92it/s]\n",
            "Training model:  14%|█▎        | 27/200 [00:00<00:01, 103.87it/s]\n",
            "Training model:  16%|█▌        | 31/200 [00:00<00:01, 96.64it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:00, 179.56it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:01, 118.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training verifier...\n",
            "\n",
            "Training verifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing shadow models: 100%|██████████| 10/10 [00:00<00:00, 226.91it/s]\n",
            "Processing independent models: 100%|██████████| 10/10 [00:00<00:00, 190.88it/s]\n",
            "Training verifier:  48%|████▊     | 143/300 [00:00<00:00, 243.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating performance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing extracted models: 100%|██████████| 5/5 [00:00<00:00, 198.54it/s]\n",
            "Testing independent models: 100%|██████████| 5/5 [00:00<00:00, 171.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Setting II:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Running experiment on Cora with Setting III\n",
            "Training target model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  14%|█▎        | 27/200 [00:00<00:00, 207.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training shadow models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▎        | 25/200 [00:00<00:00, 216.47it/s]\n",
            "Training model:  14%|█▍        | 28/200 [00:00<00:00, 210.74it/s]\n",
            "Training model:  15%|█▌        | 30/200 [00:00<00:00, 233.38it/s]\n",
            "Training model:  14%|█▍        | 28/200 [00:00<00:00, 230.21it/s]\n",
            "Training model:  17%|█▋        | 34/200 [00:00<00:00, 227.75it/s]\n",
            "Training model:  14%|█▎        | 27/200 [00:00<00:00, 203.76it/s]\n",
            "Training model:  15%|█▌        | 30/200 [00:00<00:00, 192.13it/s]\n",
            "Training model:  14%|█▍        | 28/200 [00:00<00:00, 190.28it/s]\n",
            "Training model:  14%|█▎        | 27/200 [00:00<00:00, 197.42it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:00, 202.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training independent models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▎        | 25/200 [00:00<00:00, 188.67it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 137.29it/s]\n",
            "Training model:  14%|█▍        | 29/200 [00:00<00:00, 193.27it/s]\n",
            "Training model:  14%|█▍        | 28/200 [00:00<00:01, 170.98it/s]\n",
            "Training model:  14%|█▍        | 28/200 [00:00<00:00, 189.41it/s]\n",
            "Training model:  14%|█▎        | 27/200 [00:00<00:01, 120.97it/s]\n",
            "Training model:  14%|█▍        | 28/200 [00:00<00:00, 191.57it/s]\n",
            "Training model:  15%|█▌        | 30/200 [00:00<00:01, 152.80it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:00, 229.78it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:01, 173.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training verifier...\n",
            "\n",
            "Training verifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing shadow models: 100%|██████████| 10/10 [00:00<00:00, 553.92it/s]\n",
            "Processing independent models: 100%|██████████| 10/10 [00:00<00:00, 223.24it/s]\n",
            "Training verifier:  35%|███▌      | 105/300 [00:00<00:00, 244.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating performance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing extracted models: 100%|██████████| 5/5 [00:00<00:00, 245.93it/s]\n",
            "Testing independent models: 100%|██████████| 5/5 [00:00<00:00, 208.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Setting III:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Running experiment on Cora with Setting IV\n",
            "Training target model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  16%|█▌        | 31/200 [00:00<00:00, 188.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training shadow models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  14%|█▎        | 27/200 [00:00<00:00, 195.27it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:00, 192.80it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:00, 185.52it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:00, 193.46it/s]\n",
            "Training model:  14%|█▎        | 27/200 [00:00<00:01, 163.86it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:00, 194.54it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:00, 197.07it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:00, 188.58it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:00, 188.76it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:00, 192.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training independent models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  14%|█▎        | 27/200 [00:00<00:01, 145.90it/s]\n",
            "Training model:  14%|█▍        | 29/200 [00:00<00:01, 125.63it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:00, 196.21it/s]\n",
            "Training model:  17%|█▋        | 34/200 [00:00<00:00, 184.51it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:00, 184.55it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:01, 109.23it/s]\n",
            "Training model:  15%|█▌        | 30/200 [00:00<00:00, 197.47it/s]\n",
            "Training model:  22%|██▏       | 43/200 [00:00<00:00, 184.45it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:00, 184.97it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:01, 109.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training verifier...\n",
            "\n",
            "Training verifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing shadow models: 100%|██████████| 10/10 [00:00<00:00, 274.86it/s]\n",
            "Processing independent models: 100%|██████████| 10/10 [00:00<00:00, 208.21it/s]\n",
            "Training verifier:  51%|█████     | 153/300 [00:00<00:00, 245.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating performance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing extracted models: 100%|██████████| 5/5 [00:00<00:00, 233.44it/s]\n",
            "Testing independent models: 100%|██████████| 5/5 [00:00<00:00, 177.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Setting IV:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "==================================================\n",
            "Running experiments on CiteSeer dataset\n",
            "==================================================\n",
            "\n",
            "Running experiment on CiteSeer with Setting I\n",
            "Training target model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  11%|█         | 22/200 [00:00<00:00, 185.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training shadow models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training model:  11%|█         | 22/200 [00:00<00:00, 228.77it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:00, 219.77it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:00, 223.15it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:00, 221.35it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:00, 193.58it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:00, 198.42it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:00, 202.11it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:00, 191.52it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:00, 183.78it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:00, 183.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training independent models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  11%|█         | 22/200 [00:00<00:00, 194.37it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 143.63it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 110.45it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:01, 136.80it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:00, 226.99it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 157.80it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 128.85it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 131.00it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:00, 180.52it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 132.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training verifier...\n",
            "\n",
            "Training verifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing shadow models: 100%|██████████| 10/10 [00:00<00:00, 262.92it/s]\n",
            "Processing independent models: 100%|██████████| 10/10 [00:00<00:00, 159.02it/s]\n",
            "Training verifier: 100%|██████████| 300/300 [00:01<00:00, 181.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating performance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing extracted models: 100%|██████████| 5/5 [00:00<00:00, 246.12it/s]\n",
            "Testing independent models: 100%|██████████| 5/5 [00:00<00:00, 163.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Setting I:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Running experiment on CiteSeer with Setting II\n",
            "Training target model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 144.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training shadow models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 148.84it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 151.54it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 152.47it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 147.47it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 158.21it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 159.16it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 159.87it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 153.42it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 155.13it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 156.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training independent models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 159.79it/s]\n",
            "Training model:  14%|█▎        | 27/200 [00:00<00:01, 106.59it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 110.39it/s]\n",
            "Training model:  14%|█▍        | 29/200 [00:00<00:01, 124.88it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 156.93it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 118.30it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 114.77it/s]\n",
            "Training model:  16%|█▋        | 33/200 [00:00<00:01, 126.04it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 167.28it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 114.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training verifier...\n",
            "\n",
            "Training verifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing shadow models: 100%|██████████| 10/10 [00:00<00:00, 189.93it/s]\n",
            "Processing independent models: 100%|██████████| 10/10 [00:00<00:00, 139.68it/s]\n",
            "Training verifier:  42%|████▏     | 125/300 [00:00<00:00, 223.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating performance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing extracted models: 100%|██████████| 5/5 [00:00<00:00, 169.62it/s]\n",
            "Testing independent models: 100%|██████████| 5/5 [00:00<00:00, 132.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Setting II:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Running experiment on CiteSeer with Setting III\n",
            "Training target model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 127.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training shadow models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training model:  10%|█         | 21/200 [00:00<00:01, 124.91it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 126.23it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 126.17it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 127.07it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 125.62it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 127.28it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 124.90it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 126.17it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 127.27it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 126.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training independent models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 173.31it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 115.07it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 118.93it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 127.96it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 153.73it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 102.14it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 109.44it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 102.14it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 141.09it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 116.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training verifier...\n",
            "\n",
            "Training verifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing shadow models: 100%|██████████| 10/10 [00:00<00:00, 420.35it/s]\n",
            "Processing independent models: 100%|██████████| 10/10 [00:00<00:00, 73.19it/s]\n",
            "Training verifier:  49%|████▉     | 148/300 [00:00<00:00, 180.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating performance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing extracted models: 100%|██████████| 5/5 [00:00<00:00, 112.61it/s]\n",
            "Testing independent models: 100%|██████████| 5/5 [00:00<00:00, 136.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Setting III:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Running experiment on CiteSeer with Setting IV\n",
            "Training target model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 107.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training shadow models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  13%|█▎        | 26/200 [00:00<00:01, 117.07it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 114.18it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 116.90it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:01, 116.51it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 113.17it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 115.54it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:01, 115.36it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:01, 115.53it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 115.97it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 116.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training independent models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▎        | 25/200 [00:00<00:01, 168.88it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 112.47it/s]\n",
            "Training model:  13%|█▎        | 26/200 [00:00<00:01, 116.71it/s]\n",
            "Training model:  14%|█▍        | 29/200 [00:00<00:01, 123.92it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 150.59it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 120.11it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 115.54it/s]\n",
            "Training model:  19%|█▉        | 38/200 [00:00<00:01, 121.51it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 170.88it/s]\n",
            "Training model:  14%|█▎        | 27/200 [00:00<00:01, 120.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training verifier...\n",
            "\n",
            "Training verifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing shadow models: 100%|██████████| 10/10 [00:00<00:00, 379.68it/s]\n",
            "Processing independent models: 100%|██████████| 10/10 [00:00<00:00, 70.20it/s]\n",
            "Training verifier:  78%|███████▊  | 233/300 [00:00<00:00, 244.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating performance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing extracted models: 100%|██████████| 5/5 [00:00<00:00, 109.28it/s]\n",
            "Testing independent models: 100%|██████████| 5/5 [00:00<00:00, 127.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Setting IV:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "==================================================\n",
            "Running experiments on PubMed dataset\n",
            "==================================================\n",
            "\n",
            "Running experiment on PubMed with Setting I\n",
            "Training target model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  11%|█         | 22/200 [00:00<00:01, 128.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training shadow models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 122.97it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 114.40it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 105.89it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 116.41it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 120.35it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 111.44it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 110.76it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 116.41it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 113.34it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 124.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training independent models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  11%|█         | 22/200 [00:00<00:01, 127.93it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 92.10it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 92.05it/s]\n",
            "Training model:  16%|█▋        | 33/200 [00:00<00:01, 88.66it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 129.04it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 89.90it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 92.44it/s]\n",
            "Training model:  17%|█▋        | 34/200 [00:00<00:01, 87.92it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 122.26it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 90.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training verifier...\n",
            "\n",
            "Training verifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing shadow models: 100%|██████████| 10/10 [00:00<00:00, 168.20it/s]\n",
            "Processing independent models: 100%|██████████| 10/10 [00:00<00:00, 115.63it/s]\n",
            "Training verifier:  37%|███▋      | 112/300 [00:00<00:00, 230.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating performance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing extracted models: 100%|██████████| 5/5 [00:00<00:00, 160.84it/s]\n",
            "Testing independent models: 100%|██████████| 5/5 [00:00<00:00, 114.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Setting I:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Running experiment on PubMed with Setting II\n",
            "Training target model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 77.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training shadow models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▎        | 25/200 [00:00<00:02, 76.68it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 77.63it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 78.58it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 77.96it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:02, 77.64it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 77.24it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 76.76it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 78.31it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 76.81it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:02, 77.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training independent models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▎        | 25/200 [00:00<00:02, 77.95it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:03, 55.04it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 66.33it/s]\n",
            "Training model:  22%|██▏       | 44/200 [00:00<00:02, 61.12it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:02, 71.96it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:03, 49.48it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:02, 63.05it/s]\n",
            "Training model:  17%|█▋        | 34/200 [00:00<00:02, 63.00it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:02, 76.47it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:03, 55.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training verifier...\n",
            "\n",
            "Training verifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing shadow models: 100%|██████████| 10/10 [00:00<00:00, 95.83it/s]\n",
            "Processing independent models: 100%|██████████| 10/10 [00:00<00:00, 76.78it/s]\n",
            "Training verifier:  53%|█████▎    | 159/300 [00:01<00:00, 147.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating performance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing extracted models: 100%|██████████| 5/5 [00:00<00:00, 31.57it/s]\n",
            "Testing independent models: 100%|██████████| 5/5 [00:00<00:00, 46.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Setting II:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Running experiment on PubMed with Setting III\n",
            "Training target model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 92.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training shadow models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 62.92it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 91.94it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 92.27it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 93.35it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 92.78it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 92.38it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 92.43it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 93.64it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 92.81it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 93.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training independent models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 130.05it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 91.51it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 92.71it/s]\n",
            "Training model:  14%|█▍        | 29/200 [00:00<00:01, 89.10it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:01, 122.65it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 89.82it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:01, 93.01it/s]\n",
            "Training model:  16%|█▌        | 32/200 [00:00<00:01, 88.16it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:01, 129.70it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:02, 80.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training verifier...\n",
            "\n",
            "Training verifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing shadow models: 100%|██████████| 10/10 [00:00<00:00, 445.45it/s]\n",
            "Processing independent models: 100%|██████████| 10/10 [00:00<00:00, 54.36it/s]\n",
            "Training verifier:  51%|█████     | 152/300 [00:00<00:00, 194.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating performance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing extracted models: 100%|██████████| 5/5 [00:00<00:00, 93.61it/s]\n",
            "Testing independent models: 100%|██████████| 5/5 [00:00<00:00, 100.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Setting III:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Running experiment on PubMed with Setting IV\n",
            "Training target model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  13%|█▎        | 26/200 [00:00<00:02, 64.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training shadow models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 65.55it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 67.20it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:02, 66.91it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:02, 66.75it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:02, 67.33it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:02, 67.37it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 66.88it/s]\n",
            "Training model:  11%|█         | 22/200 [00:00<00:02, 66.69it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:02, 66.92it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:02, 66.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training independent models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training model:  12%|█▏        | 23/200 [00:00<00:02, 76.96it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:03, 55.70it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:02, 66.94it/s]\n",
            "Training model:  20%|█▉        | 39/200 [00:00<00:02, 64.33it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:02, 77.23it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:03, 55.66it/s]\n",
            "Training model:  12%|█▎        | 25/200 [00:00<00:02, 66.71it/s]\n",
            "Training model:  15%|█▌        | 30/200 [00:00<00:02, 63.84it/s]\n",
            "Training model:  12%|█▏        | 24/200 [00:00<00:02, 76.76it/s]\n",
            "Training model:  12%|█▏        | 23/200 [00:00<00:03, 56.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training verifier...\n",
            "\n",
            "Training verifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing shadow models: 100%|██████████| 10/10 [00:00<00:00, 382.06it/s]\n",
            "Processing independent models: 100%|██████████| 10/10 [00:00<00:00, 39.97it/s]\n",
            "Training verifier:  50%|████▉     | 149/300 [00:00<00:00, 234.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating performance...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing extracted models: 100%|██████████| 5/5 [00:00<00:00, 73.05it/s]\n",
            "Testing independent models: 100%|██████████| 5/5 [00:00<00:00, 76.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Setting IV:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "\n",
            "==================================================\n",
            "FINAL RESULTS SUMMARY\n",
            "==================================================\n",
            "\n",
            "Cora Dataset:\n",
            "\n",
            "Setting I:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Setting II:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Setting III:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Setting IV:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "CiteSeer Dataset:\n",
            "\n",
            "Setting I:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Setting II:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Setting III:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Setting IV:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "PubMed Dataset:\n",
            "\n",
            "Setting I:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Setting II:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Setting III:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n",
            "\n",
            "Setting IV:\n",
            "Accuracy: 1.0000\n",
            "False Positive Rate: 0.0000\n",
            "False Negative Rate: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJyjzOJM6W09"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}